# 考察メモ

- 解が出る方針ではなく、良い解が出る方針を探す

# 10/14

- 指数分布の推定？
- 大小関係しかわからない

## 比較で得られる情報

- (A+d) - (B+c) > 0
- A - B > 0

- A - B - c + d > 0
    - A - B > c - d

- (A+d) - (B+c) > 0
- A - B < 0

- d - c > B - A

## 入力

- N: rand_int(30, 100)
- D: rand_int(2, floor(N / 4))
    - 2 <= D <= N / 4
- Q: round(N * 2 ^ rand_double(1, 5))
    - 2N <= Q <= 32N
    - 8D <= Q <= 128D

## 考察ポイント

- どれを入れ替えるか、どう判断する？
    - 序盤はなるべく重いもの、終盤は軽いものを入れ替えるのがよさそう？
    - 入れ替えた時に変動があったかどうか、だけが情報となる
    - => 各アイテムの重量の推定値があると嬉しい
- モンテカルロが効きそう？
- 変動が大きくなった時、良い解になっているかどうか、どう判断する？
    - 必ずしもグループに入っているものを検証する必要はない

- 集合の重さははどういう分布に従うか

## 方針

- 初期解作って、いじって大小関係が変わるところを探す
- 一個ずつ試す

## 方針1: 初期解作って、いじって大小関係が変わるところを探す

- ランダムに割り当てて、大小関係が入れ替わるところを探す
- 大きいところから小さいところに移動させるとよさそう
    - 常に集合の大小関係を保持しておく
    - バブルソートの要領でO(D)で更新できそう

```rust
groups: Vec<Vec<usize>>;
rank: Vec<usize>;

fn sort_groups(groups: &Vec<Vec<usize>>) -> Vec<usize>;

fn insert_group(g_idx: usize, from_up: bool);
```

1. ランダムにグループに割り振る
2. ソートして順位をつける（`O(D * log D)`）
3. 一番重いグループから軽いグループに移す
4. 順位を更新する（`O(D)`）
5. 3.に戻る

## n個の大小関係が知りたい時、最低何回の天秤操作でわかる？

- ソートと同じことをやる
- クイックソートを実装できればO(D * log D)
    - 最悪O(D^2)
- Dが大きく、Qが少ないケースだとダメそう

```rust
// デバッグ用
let rank_correct = sort_groups(&groups, input, interactor);
if rank.len() == rank_correct.len() {
    assert_eq!(rank_correct, rank);
}
```

- しばらくすると、更新されなくなる（局所解にはまる）

## 重さを知ると、最適解がわかる

- 焼きなましで（ほぼ）最適解がわかる

## 考察

- 大きい方と小さい方を近づける
    - グループを2つ選んで大小関係を調べて、
    - その中から大小関係が入れ替わっている集合を選んでswapする
    - グループの大小関係が入れ替わっていなければ改善している
- 都度ソートする必要はない
- 比較結果を保持すれば、同じやつは2回もする必要はない
    - 保持していれば、得ようとしている大小関係もわかるかも
    - 大小関係が単調なペアを通って、経路が存在すれば良い
- 順位がわかれば、重さもなんとなく推定できる
    - 3つのうち、最下位だったらxくらい、とか

## 改善点

- 順位の更新は二分探索できそう
    - Dが大きいケースは効きそうだが、小さいケースは悪化しそう
- 一番大きいところから1個抜いた重さと、一番小さいのを比べて、逆転していたら操作する必要がない

## 課題と改善方針

1. クエリ数が足りていない
    - 該当するケースは少なそうなので優先度は低いか
2. 局所解にはまっている
    - 真ん中の方に入ったら良い？
    - swapが欲しい？
        - 隣のやつとswap？
        - 1:2でswap
        - 最初にswapしようとしているもの同士を比べて、意味があるかどうかを調べる
3. Dが大きいケースに弱い
    - 方針2が効きそう
4. 各荷物の重さをなんとなく推定したい

## 方針2: 2つグループを選択して、近づけるようにswapを繰り返す

- 大きい方と小さい方を近づける
    - グループを2つ選んで大小関係を調べて、
    - その中から大小関係が入れ替わっている集合を選んでswapする
    - グループの大小関係が入れ替わっていなければ改善している
    - swapする個数は何個でも良い

# 10/15

- swapが思ったほど効かない
    - バグ直すと効いた

## 課題

- 終盤は2つ以上swapしたい
    - ギリギリを攻めるには、徐々に錘を追加していく処理が欲しい
- 二分探索した方が良い場面がありそう
    - binary_searchかlinear_searchかうまく判断したい
- 比較結果を保持しておいて活用したい

- 一番大きいのと小さいのが残る可能性がある

- 一番小さいグループが1個だけしか荷物がないパターンがある

- 大きく分けて、以下が必要そう
    - クエリ回数の削減
    - 有効な操作の推論
    - （Qが少ない時の別解法）

- パラメータ調整

## 考察

- グループ内の大小関係を図ると、基準ができるため、クエリ回数を削減することができる
- 改悪を受け入れることはできなさそう
    - 今の解がどれくらい良いか知ることはできないので、、
        - 動かせるかどうかで、局所解にはまっているか判断できるかも？
        - ちょっと動かすと大小関係が入れ替わっちゃうなら近い状態になっているかも？
- moveは最初に偏らせた方が良い？

### 改善1: 比較結果の活用

1. 比較した情報の保持
    - ハッシュ化して、すでに存在すればその情報を使用する
2. すでにある比較結果から推論
    - グラフを構築して、辿れるところに行く

--- done ---

3. （すでにある比較結果から、どれくらい重みが離れているか推論）
    - 近いやつだけわかれば良い？

### 改善2: 2つ以上のswap

1. ランダムに2つ以上swapしてみる
    - 弱そう
2. 1:2のswapを追加
    - `a<b => a+c<b`となる`c`を探す
    - `a>b => a<b+c`となる`c`を探す

--- done ---

3. 1:nのswapを追加
    - 望んだ大小関係になるまで徐々に追加する
4. n:nのswapを追加

### 改善3: 集合の選び方

1. 重い方と軽い方からランダムに選ぶ
    - 端っこから選ばれやすくする
        - 遠いやつが改善しやすい & 改善幅が大きい
    - 幅を広げた後も一様分布じゃなくする

## 細かい改善策

- 集合の選び方
    - ソートしなくて良いなら操作回数は減らせる
    - 端っこから選ばれやすくする
        - 遠いやつが改善しやすい & 改善幅が大きい
    - 幅を広げた後も一様分布じゃなくする
- アイテムの選び方
    - ランダムに選ばない
        - 小さい順に選ぶ？
            - 集合を与えたら、一番小さい・大きい"可能性があるもの"を返す関数の実装
        - 真ん中ら辺から選ぶ？
- 行動の選び方
    - まだでこぼこなら、重さが遠い・大きいものを選ぶ
    - 終盤は重さが近い・小さいものを選ぶ
- 操作回数の削減
    - 最初はmoveだけにする
    - 直接比較するより、間接的に比較した方が良い場合がありそう
        - よく考えるとなさそう
    - 重さの推論
        - 差分を使える？
            - `b>c`の時`A+c>D`なら`A+b>D`
        - 部分集合を使える？
            - `a in A, a>c`の時、`A>c`
    - `d`が小さい時、あるいは最後の方である程度均一な時は、ソートする必要なさそう

## 観察

- 割と最後の方まで操作が起きている
    - 操作回数を増やす・有効な操作を増やすことを重視した方が良いかも

## 今後

1. 1:2のswapの実装
    - ランダムに試す
2. 推論を強くする
    - 差分
        - 集合の差分が1つのやつで、差分の大小関係がわかっているものに対して辺を伸ばせば良さそう
    - 部分集合
        - 大きい方が重い
        - 小さい方が軽い
        - 包含する・包含している集合があれば辺を伸ばすようにすれば良さそう
    - `u128`のビットで管理した方が良いかも？
        - なんか乱数を引いている回数が減るからっぽい
            - 後で検証するけど、乱数を引く回数を同じにしたら同じなった
4. 1:n、n:nのswapの実装
    - 1:2が強ければ先に実装する
        - そこまで強くなかった
5. 細かい改善
    - 小さい順に試す、など

## 可視化項目

- 改善が全ターンのどこまで行われているか
- 探索がどの深さで見つかっているか

# 10/16

- そろそろ高速化が必要かも
    - 探索が重い
    - 辺を追加するのは得しかないはずなので、重複していない確認する
        - 冗長な辺を減らす？
    - 見つかる時は、どの深さで見つかる？
    - groupsのコピーをやめる
- アイテムの選び方を工夫する方が先かも
- 軽い順で選ぶ

## DONE:

- UpdateRankBinarySearchはlとrを工夫できる
    - 少し効いた
- 端っこほど選ばれるようにする
    - 効いた
- ある程度グループ固定して試行した方が良さそう
    - 最後に試す
- 最後の方はソートをやめる
    - 微妙そう？

## 課題

- Qが小さい時の対策
- 有望なアイテムを選ぶようにする
    - 自明にダメなアイテムは選ばないようにする（選んでも良いが、クエリが走らないようにする）
    - なるべく一番重さが近いアイテムと比較した方が良さそう（副作用はありそう）

- VecDequeが遅い？
    - https://kumagi.hatenadiary.org/entry/20130202/1359815752

## 差分の辺の追加、調査

- 実行時間伸ばすと効いている
- A+a>B>A+cならa>c（辺を追加するタイミングで、全て辿れば良い？）
    - 追加すると悪化した、実行時間がネックっぽい

## MAYBE

# 10/17

## 最後に試す改善

- ある程度グループ固定して試行する
    - 効果少なそうだった

## 当面の方針

- 調査
    - グラフ上の探索
        - ちゃんとやれば必ず上がる
- 考察
    - 有望なアイテムの選択
        - 一番改善幅がありそうだが、上がらない時は上がらなそう
    - 集合の選び方の工夫
        - 集合に含まれる個数の情報を使う
    - Qが小さい時の工夫
        - 特にないか？
- 実装
    - 高速化
        - VecDequeを止める
        - groupsのコピーをやめる

## 考察

- 集合に含まれる個数の情報を使っていないよ、、
    - 個数が似ているもの同士入れ替えた方が良い、とか？

##　グラフ上の探索の調査

- ノード数は多くなさそう（<=1000）
- 辺数が多そう
    - 冗長な辺はないんだよねー
    - 使い道がない辺は追加しない？
- ハッシュ、Dequeが重そう

## 有望なアイテムの選択の考察

- `a<b<c`の関係にあるなら、aとcを試すよりaとbを試した方が成功率は高い
- `a<b<c<d`と`a<e<f`があるなら、bの方がeより小さそう

- 1/n

# 10/21

- 高速化
    - VecDequeを止める
    - groupsのコピーをやめる
    - setを共有したい
    - 集合をbitで管理する
    - そこそこ効きそう
- 経路探索の工夫
    - 深さの調整
    - ノード間に辺を作る
        - あんまり意味なさそう
- スワップの工夫
    - 選ぶアイテムの工夫
    - スタートを1:1でやる必要はない
        - `n:m`で取って、減らす or 増やす
- 深さは5くらいで十分そう
    - tl=30、depth=20にしてもあまり変わらない
    ```
    python3 run.py -e -a sub9-faster-depth-20-tl-30 -b sub9-faster-depth-5
    ```

- 最後の調整
    - パラメータ調整
    - 集合の選び方
    - qに応じた近傍の調整
        - あまり効果なさそう
    - 最初はランダムに選ぶ
        - 実質そうなっていそう

## 今後の方針

- swap
    - n:nは難しそう
        - なんでだろうねー
- qが小さい時の対処
- `add_edges_with_search`の追求
    - 高速化の後？
- 高速化
    - 探索の高速化
- 細かい調整

## 残りTODO

- 1:1スワップ時に良いアイテムを選ぶ
- 高速化
- `add_edges_with_search`の追求
    - むしろ悪化する
        - `add_edge`の計算コストが増えるデメリットが大きそう

## 有効な操作を増やす

- 推論する
    - ある程度辿れていそうなら、意味なさそう、、

## 効果の大きい操作を増やす

- 最初は幅の大きい操作を優先する
    - あんまり効果なさそう

## 操作回数を増やす

- ソートをなくす？
    - 弱そう
- update_rankをなくす？
    - 前試した時は弱かった

## 解法の整理

1. 各アイテムをランダムにグループに割り振る
2. グループの重さをソートする
3. 以下の操作のいずれかを行う
    1. 一番重いグループから一番軽いグループに一つアイテムを移動する
    2. 一番重いグループと一番軽いグループのアイテムを交換する
        - 1:1、1:nで交換する
4. 操作が成立したら、グループの重さ順を更新する
